<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Random Forest Complete Guide with Visualizations</title>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <style>
        * { margin: 0; padding: 0; box-sizing: border-box; }
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: #333;
            line-height: 1.6;
        }
        .container { max-width: 1200px; margin: 0 auto; padding: 20px; }
        header { 
            background: white; 
            padding: 30px; 
            border-radius: 10px; 
            margin-bottom: 30px; 
            box-shadow: 0 10px 30px rgba(0,0,0,0.2); 
            text-align: center; 
        }
        h1 { color: #667eea; margin-bottom: 10px; font-size: 2.5em; }
        .subtitle { color: #666; font-size: 1.1em; }
        .nav-tabs { 
            display: flex; 
            gap: 10px; 
            margin-bottom: 30px; 
            flex-wrap: wrap; 
            justify-content: center; 
        }
        .nav-tabs button { 
            padding: 12px 25px; 
            background: white; 
            border: 2px solid #667eea; 
            border-radius: 5px; 
            cursor: pointer; 
            font-size: 1em; 
            font-weight: 600; 
            color: #667eea; 
            transition: all 0.3s; 
        }
        .nav-tabs button.active { 
            background: #667eea; 
            color: white; 
            transform: translateY(-2px); 
            box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4); 
        }
        .nav-tabs button:hover { transform: translateY(-2px); }
        .tab-content { display: none; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 10px 30px rgba(0,0,0,0.1); animation: fadeIn 0.5s; }
        .tab-content.active { display: block; }
        @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
        h2 { color: #667eea; margin: 25px 0 15px 0; font-size: 1.8em; border-bottom: 3px solid #764ba2; padding-bottom: 10px; }
        h3 { color: #764ba2; margin: 20px 0 10px 0; font-size: 1.3em; }
        .content-section { margin-bottom: 25px; }
        .viz-container { margin: 25px 0; padding: 20px; background: #f8f9ff; border-radius: 8px; border-left: 4px solid #667eea; }
        .code-block { background: #2d2d2d; color: #f8f8f2; padding: 15px; border-radius: 5px; overflow-x: auto; margin: 15px 0; font-family: 'Courier New', monospace; font-size: 0.9em; line-height: 1.4; }
        .key-point { background: #fff3cd; border-left: 4px solid #ffc107; padding: 15px; margin: 15px 0; border-radius: 5px; }
        .advantage { background: #d4edda; border-left: 4px solid #28a745; padding: 12px; margin: 10px 0; border-radius: 5px; }
        .disadvantage { background: #f8d7da; border-left: 4px solid #dc3545; padding: 12px; margin: 10px 0; border-radius: 5px; }
        table { width: 100%; border-collapse: collapse; margin: 15px 0; }
        th { background: #667eea; color: white; padding: 12px; text-align: left; font-weight: 600; }
        td { padding: 12px; border-bottom: 1px solid #e0e0e0; }
        tr:hover { background: #f5f5f5; }
        .comparison-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 20px 0; }
        .card { background: #f8f9ff; padding: 20px; border-radius: 8px; border: 2px solid #667eea; text-align: center; }
        .card h4 { color: #667eea; margin-bottom: 10px; }
        .metric { font-size: 1.8em; font-weight: bold; color: #764ba2; margin: 10px 0; }
        .interactive-section { background: #f0f4ff; padding: 20px; border-radius: 8px; margin: 20px 0; }
        .slider-group { margin: 15px 0; }
        input[type="range"] { width: 100%; margin: 10px 0; }
        .parameter-display { background: white; padding: 15px; border-radius: 5px; margin: 10px 0; font-family: monospace; }
        footer { text-align: center; padding: 20px; color: white; margin-top: 40px; }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üå≥ Random Forest Complete Guide</h1>
            <p class="subtitle">Master Ensemble Learning with Visualizations & Interactive Tools</p>
        </header>

        <div class="nav-tabs">
            <button class="tab-btn active" onclick="switchTab('overview')">Overview</button>
            <button class="tab-btn" onclick="switchTab('concept')">How It Works</button>
            <button class="tab-btn" onclick="switchTab('bagging')">Bagging</button>
            <button class="tab-btn" onclick="switchTab('params')">Hyperparameters</button>
            <button class="tab-btn" onclick="switchTab('importance')">Feature Importance</button>
            <button class="tab-btn" onclick="switchTab('code')">Implementation</button>
            <button class="tab-btn" onclick="switchTab('comparison')">Comparisons</button>
            <button class="tab-btn" onclick="switchTab('case')">Case Study</button>
        </div>

        <!-- OVERVIEW TAB -->
        <div id="overview" class="tab-content active">
            <h2>üéØ What is Random Forest?</h2>
            <div class="content-section">
                <p>Random Forest is an ensemble learning algorithm that combines multiple decision trees to create a powerful, robust predictive model. Instead of trusting a single tree, it builds many trees and aggregates their predictions.</p>
                
                <h3>Key Characteristics</h3>
                <div class="key-point">
                    <strong>Ensemble Method</strong><br>
                    Combines multiple weak learners (decision trees) into a strong learner
                </div>
                <div class="key-point">
                    <strong>Two Sources of Randomness</strong>
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>Bootstrap sampling (random data subsets)</li>
                        <li>Random feature selection at each split</li>
                    </ul>
                </div>
                
                <h3>Why Random Forest?</h3>
                <div class="comparison-grid">
                    <div class="card">
                        <h4>üå≤ Forest</h4>
                        <p>Multiple decision trees combined together</p>
                    </div>
                    <div class="card">
                        <h4>üé≤ Random</h4>
                        <p>Data and features randomly selected for diversity</p>
                    </div>
                </div>
                
                <h3>Classification vs Regression</h3>
                <table>
                    <thead>
                        <tr><th>Aspect</th><th>Classification</th><th>Regression</th></tr>
                    </thead>
                    <tbody>
                        <tr><td><strong>Target</strong></td><td>Categorical (Yes/No, A/B/C)</td><td>Continuous (1.5, 2.3, 100)</td></tr>
                        <tr><td><strong>Aggregation</strong></td><td>Majority voting</td><td>Average of predictions</td></tr>
                        <tr><td><strong>Output</strong></td><td>Class label + probability</td><td>Numerical value</td></tr>
                    </tbody>
                </table>
            </div>
        </div>

        <!-- CONCEPT TAB -->
        <div id="concept" class="tab-content">
            <h2>üîÑ How Random Forest Works</h2>
            <div class="content-section">
                <h3>Step-by-Step Algorithm</h3>
                <div class="viz-container">
                    <h4>Algorithm Flow</h4>
                    <div id="algorithmFlow" style="height: 400px;"></div>
                </div>
                
                <h3>The Process</h3>
                <div style="background: #f8f9ff; padding: 20px; border-radius: 8px; margin: 20px 0;">
                    <p><strong>Step 1: Bootstrap Sampling</strong><br>
                    For each tree, randomly sample N rows <strong>WITH replacement</strong> from the dataset</p>
                    
                    <p style="margin-top: 15px;"><strong>Step 2: Build Decision Trees</strong><br>
                    For each sample, build a decision tree by:
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>Randomly selecting m features (‚àöm classification or m/3 regression)</li>
                        <li>Finding the best split among selected features</li>
                        <li>Recursively splitting until max depth or minimum samples</li>
                    </ul></p>
                    
                    <p style="margin-top: 15px;"><strong>Step 3: Aggregate Predictions</strong><br>
                    For new data:
                    <ul style="margin-left: 20px; margin-top: 10px;">
                        <li>Classification: Majority vote from all trees</li>
                        <li>Regression: Average predictions from all trees</li>
                    </ul>
                </div>
                
                <h3>Example: Loan Default Prediction</h3>
                <div id="exampleViz" style="height: 400px; margin: 20px 0;"></div>
            </div>
        </div>

        <!-- BAGGING TAB -->
        <div id="bagging" class="tab-content">
            <h2>üì¶ Bootstrap Aggregating (Bagging)</h2>
            <div class="content-section">
                <h3>What is Bagging?</h3>
                <p>Bagging (Bootstrap Aggregating) is the foundation of Random Forest. It reduces variance by creating multiple training sets through random sampling <strong>WITH replacement</strong>.</p>
                
                <h3>Bootstrap Sampling Visualization</h3>
                <div id="baggingViz" style="height: 350px; margin: 20px 0;"></div>
                
                <h3>Key Statistics</h3>
                <div class="comparison-grid">
                    <div class="card">
                        <h4>Out-of-Bag Samples</h4>
                        <div class="metric">36.8%</div>
                        <p>Data not used in bootstrap sample</p>
                    </div>
                    <div class="card">
                        <h4>In-Bag Samples</h4>
                        <div class="metric">63.2%</div>
                        <p>Data used in bootstrap sample</p>
                    </div>
                </div>
                
                <h3>Bias-Variance Tradeoff</h3>
                <table>
                    <thead><tr><th>Property</th><th>Single Model</th><th>Bagged Model</th></tr></thead>
                    <tbody>
                        <tr><td><strong>Bias</strong></td><td>Low</td><td>Low (unchanged)</td></tr>
                        <tr><td><strong>Variance</strong></td><td>High ‚ùå</td><td>Reduced ‚úÖ</td></tr>
                        <tr><td><strong>Overfitting</strong></td><td>High</td><td>Significantly reduced</td></tr>
                        <tr><td><strong>Interpretability</strong></td><td>High</td><td>Lower (multiple trees)</td></tr>
                    </tbody>
                </table>
                
                <h3>Why Random Features Matter</h3>
                <p style="margin-top: 20px;">Without random feature selection, all trees would split on the strongest feature first, creating highly correlated trees that don't reduce variance effectively. Random feature selection decorrelates trees, improving ensemble performance.</p>
            </div>
        </div>

        <!-- HYPERPARAMETERS TAB -->
        <div id="params" class="tab-content">
            <h2>‚öôÔ∏è Hyperparameter Tuning</h2>
            <div class="content-section">
                <h3>Interactive Parameter Exploration</h3>
                <div class="interactive-section">
                    <div class="slider-group">
                        <label><strong>n_estimators (Trees):</strong> <span id="ntrees">100</span></label>
                        <input type="range" min="10" max="500" step="10" value="100" oninput="updateParams('ntrees', this.value)">
                        <p style="font-size: 0.9em; color: #666;">More trees = better accuracy (diminishing returns after ~200)</p>
                    </div>
                    <div class="slider-group">
                        <label><strong>max_depth (Tree Depth):</strong> <span id="maxdepth">15</span></label>
                        <input type="range" min="1" max="50" step="1" value="15" oninput="updateParams('maxdepth', this.value)">
                        <p style="font-size: 0.9em; color: #666;">Controls overfitting: shallow = underfitting, deep = overfitting</p>
                    </div>
                    <div class="slider-group">
                        <label><strong>min_samples_split:</strong> <span id="minsplit">5</span></label>
                        <input type="range" min="2" max="50" step="1" value="5" oninput="updateParams('minsplit', this.value)">
                        <p style="font-size: 0.9em; color: #666;">Minimum samples required to split a node</p>
                    </div>
                    <div class="parameter-display">
                        <strong>Current Configuration:</strong><br>
                        RandomForestClassifier(n_estimators=<span id="displaytrees">100</span>, max_depth=<span id="displaydepth">15</span>, min_samples_split=<span id="displaysplit">5</span>)
                    </div>
                </div>
                
                <h3>Tuning Strategies</h3>
                <table>
                    <thead><tr><th>Parameter</th><th>Range</th><th>Effect</th><th>Tuning Tip</th></tr></thead>
                    <tbody>
                        <tr><td><strong>n_estimators</strong></td><td>50-500</td><td>More trees = better, slower</td><td>Start at 100, increase until validation plateaus</td></tr>
                        <tr><td><strong>max_depth</strong></td><td>5-30</td><td>Controls complexity</td><td>Use 10-20 for most datasets</td></tr>
                        <tr><td><strong>min_samples_split</strong></td><td>2-20</td><td>Reduces overfitting if high</td><td>Try 2, 5, 10</td></tr>
                        <tr><td><strong>max_features</strong></td><td>‚àöm/log2</td><td>Feature diversity</td><td>‚àöm for classification, log2 alternative</td></tr>
                    </tbody>
                </table>
            </div>
        </div>

        <!-- FEATURE IMPORTANCE TAB -->
        <div id="importance" class="tab-content">
            <h2>üìä Feature Importance</h2>
            <div class="content-section">
                <h3>How Feature Importance is Calculated</h3>
                <p>Random Forest measures feature importance using <strong>Mean Decrease in Impurity (MDI)</strong>: the average reduction in impurity (Gini/Entropy) caused by each feature across all trees.</p>
                
                <h3>Titanic Dataset - Feature Importance Example</h3>
                <div id="importanceViz" style="height: 400px; margin: 20px 0;"></div>
                
                <h3>Interpretation Guide</h3>
                <div style="background: #f8f9ff; padding: 20px; border-radius: 8px; margin: 20px 0;">
                    <p><strong>Top Features Example:</strong></p>
                    <ul style="margin: 15px 0 0 20px;">
                        <li><strong>Sex (0.32)</strong> - 32% importance - strongest predictor (females had higher survival)</li>
                        <li><strong>Fare (0.28)</strong> - 28% importance - wealthier passengers more likely to survive</li>
                        <li><strong>Age (0.18)</strong> - 18% importance - children prioritized in lifeboats</li>
                        <li><strong>Pclass (0.15)</strong> - 15% importance - first-class passengers had better access</li>
                        <li><strong>Embarked (0.07)</strong> - 7% importance - less influential than others</li>
                    </ul>
                </div>
                <div class="key-point">
                    <strong>Important Caveat:</strong> MDI is biased toward high-cardinality features. For more reliable analysis, consider Permutation Importance or SHAP values.
                </div>
            </div>
        </div>

        <!-- CODE TAB -->
        <div id="code" class="tab-content">
            <h2>üíª Python Implementation</h2>
            <div class="content-section">
                <h3>Step 1: Import Libraries</h3>
                <div class="code-block">from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd</div>
                
                <h3>Step 2: Prepare Data</h3>
                <div class="code-block">df = pd.read_csv('data.csv')
X = df.drop('target', axis=1)
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)</div>
                
                <h3>Step 3: Train Model</h3>
                <div class="code-block">rf = RandomForestClassifier(
    n_estimators=100, 
    max_depth=15, 
    min_samples_split=5, 
    max_features='sqrt', 
    oob_score=True, 
    random_state=42, 
    n_jobs=-1
)
rf.fit(X_train, y_train)
print(f"OOB Score: {rf.oob_score_:.4f}")</div>
                
                <h3>Step 4: Make Predictions</h3>
                <div class="code-block">ypred = rf.predict(X_test)
accuracy = accuracy_score(y_test, ypred)
print(f"Test Accuracy: {accuracy:.4f}")
print(classification_report(y_test, ypred))</div>
                
                <h3>Step 5: Extract Feature Importance</h3>
                <div class="code-block">feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)
print(feature_importance.head(10))</div>
            </div>
        </div>

        <!-- COMPARISON TAB -->
        <div id="comparison" class="tab-content">
            <h2>‚öîÔ∏è Random Forest vs Other Algorithms</h2>
            <div class="content-section">
                <h3>Algorithm Comparison</h3>
                <div id="comparisonViz" style="height: 400px; margin: 20px 0;"></div>
                
                <h3>Detailed Comparison Table</h3>
                <table>
                    <thead><tr><th>Aspect</th><th>Random Forest</th><th>Decision Tree</th><th>Gradient Boost</th><th>Logistic Reg</th></tr></thead>
                    <tbody>
                        <tr><td><strong>Accuracy</strong></td><td>‚≠ê‚≠ê‚≠ê‚≠ê</td><td>‚≠ê‚≠ê‚≠ê</td><td>‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê</td><td>‚≠ê‚≠ê‚≠ê</td></tr>
                        <tr><td><strong>Overfitting Risk</strong></td><td>Low ‚úÖ</td><td>High ‚ùå</td><td>Medium</td><td>Low ‚úÖ</td></tr>
                        <tr><td><strong>Interpretability</strong></td><td>Medium</td><td>High ‚úÖ</td><td>Low</td><td>Very High ‚úÖ</td></tr>
                        <tr><td><strong>Training Speed</strong></td><td>Fast ‚úÖ</td><td>Very Fast</td><td>Slow</td><td>Very Fast</td></tr>
                        <tr><td><strong>Prediction Speed</strong></td><td>Medium</td><td>Very Fast ‚úÖ</td><td>Slow</td><td>Very Fast ‚úÖ</td></tr>
                        <tr><td><strong>Feature Scaling</strong></td><td>Not needed ‚úÖ</td><td>Not needed ‚úÖ</td><td>Not needed ‚úÖ</td><td>Recommended</td></tr>
                    </tbody>
                </table>
                
                <h3>When to Use Random Forest</h3>
                <div class="advantage">
                    <strong>Use RF when:</strong> You have tabular data, need high accuracy, want feature importance, have time for training, need generalization
                </div>
                <div class="disadvantage">
                    <strong>Avoid RF when:</strong> Need real-time predictions, want high interpretability, have very imbalanced data, need extrapolation beyond training range
                </div>
            </div>
        </div>

        <!-- CASE STUDY TAB -->
        <div id="case" class="tab-content">
            <h2>üìà Case Study: Titanic Survival Prediction</h2>
            <div class="content-section">
                <h3>Problem Statement</h3>
                <p>Predict which Titanic passengers survived based on 11 features (Age, Sex, Fare, Class, etc.)</p>
                
                <h3>Dataset Overview</h3>
                <table>
                    <thead><tr><th>Metric</th><th>Value</th></tr></thead>
                    <tbody>
                        <tr><td>Total Passengers</td><td>891</td></tr>
                        <tr><td>Survived</td><td>342 (38.4%)</td></tr>
                        <tr><td>Didn't Survive</td><td>549 (61.6%)</td></tr>
                        <tr><td>Number of Features</td><td>11</td></tr>
                    </tbody>
                </table>
                
                <h3>Model Performance</h3>
                <div id="caseStudyViz" style="height: 350px; margin: 20px 0;"></div>
                
                <h3>Results Summary</h3>
                <div class="comparison-grid">
                    <div class="card">
                        <h4>Accuracy</h4>
                        <div class="metric">86.5%</div>
                    </div>
                    <div class="card">
                        <h4>Precision (Survived)</h4>
                        <div class="metric">0.84</div>
                    </div>
                    <div class="card">
                        <h4>Recall (Survived)</h4>
                        <div class="metric">0.77</div>
                    </div>
                    <div class="card">
                        <h4>F1-Score</h4>
                        <div class="metric">0.80</div>
                    </div>
                </div>
                
                <h3>Key Insights</h3>
                <div style="background: #f8f9ff; padding: 20px; border-radius: 8px; margin: 20px 0;">
                    <p><strong>Top 3 Predictive Factors:</strong></p>
                    <ol style="margin: 15px 0 0 20px;">
                        <li><strong>Sex (32% importance)</strong> - Women had significantly higher survival rate</li>
                        <li><strong>Fare (28% importance)</strong> - Wealthier passengers had better survival chances</li>
                        <li><strong>Age (18% importance)</strong> - Children were prioritized in lifeboats</li>
                    </ol>
                </div>
                
                <h3>Key Learnings</h3>
                <div class="key-point">
                    Random Forest achieved 86.5% accuracy with minimal feature engineering, demonstrating its power for real-world classification problems without extensive preprocessing.
                </div>
            </div>
        </div>
    </div>

    <footer>
        <p>üå≥ Random Forest Complete Guide | Data Science & Machine Learning 2025</p>
    </footer>

    <script>
        function switchTab(tabName) {
            // Hide all tabs
            document.querySelectorAll('.tab-content').forEach(tab => tab.classList.remove('active'));
            document.querySelectorAll('.tab-btn').forEach(btn => btn.classList.remove('active'));
            
            // Show selected tab
            document.getElementById(tabName).classList.add('active');
            event.target.classList.add('active');
            
            // Trigger resize for Plotly charts
            setTimeout(() => {
                Plotly.Plots.resize('algorithmFlow');
                Plotly.Plots.resize('exampleViz');
                Plotly.Plots.resize('baggingViz');
                Plotly.Plots.resize('importanceViz');
                Plotly.Plots.resize('comparisonViz');
                Plotly.Plots.resize('caseStudyViz');
            }, 100);
        }

        // Parameter updates
        function updateParams(param, value) {
            document.getElementById(param).textContent = value;
            if (param === 'ntrees') document.getElementById('displaytrees').textContent = value;
            else if (param === 'maxdepth') document.getElementById('displaydepth').textContent = value;
            else if (param === 'minsplit') document.getElementById('displaysplit').textContent = value;
        }

        // Create visualizations
        function createVisualizations() {
            // Algorithm Flow Chart
            const algorithmData = [{
                x: ['Bootstrap', 'Build', 'Random', 'Make', 'Aggregate'],
                y: [20, 60, 60, 40, 80],
                type: 'scatter', mode: 'lines+markers+text',
                marker: { size: 15, color: '#667eea' },
                line: { width: 3, color: '#667eea' },
                text: ['Create 100+', 'Build Tree\nEach', 'Use ‚àöm\nFeatures', 'Pass Through\nAll Trees', 'Vote/Average'],
                textposition: 'top center',
                textfont: { size: 11, color: '#333' }
            }];
            Plotly.newPlot('algorithmFlow', algorithmData, {
                title: 'Random Forest Algorithm Flow',
                xaxis: { title: 'Step' },
                yaxis: { title: 'Process Complexity', range: [0, 100] },
                hovermode: 'closest',
                margin: { t: 50, b: 50, l: 60, r: 60 },
                responsive: true
            });

            // Example Visualization
            const exampleData = [{
                x: ['Tree 1', 'Tree 2', 'Tree 3', 'Tree 4', 'Tree 5'],
                y: [1, 0, 1, 1, 0],
                type: 'bar',
                marker: { color: ['#28a745', '#dc3545', '#28a745', '#28a745', '#dc3545'] },
                text: ['YES', 'NO', 'YES', 'YES', 'NO'],
                textposition: 'outside'
            }];
            Plotly.newPlot('exampleViz', exampleData, {
                title: 'Loan Default Prediction - Majority Vote (60% Default)',
                xaxis: { title: 'Individual Trees' },
                yaxis: { title: 'Prediction (1=Default, 0=No Default)', range: [-0.2, 1.5] },
                margin: { t: 50, b: 50, l: 60, r: 60 },
                responsive: true
            });

            // Bagging Visualization
            const baggingData = [{
                x: ['Sample 1\n(A,B,A,D,C)', 'Sample 2\n(B,C,D,D,E)', 'Sample 3\n(C,E,A,B,E)'],
                y: [5, 5, 5],
                type: 'bar',
                marker: { color: ['#667eea', '#764ba2', '#667eea'] },
                text: ['Tree 1', 'Tree 2', 'Tree 3'],
                textposition: 'outside'
            }];
            Plotly.newPlot('baggingViz', baggingData, {
                title: 'Bootstrap Aggregating (Bagging) - Random Sampling with Replacement',
                xaxis: { title: 'Bootstrap Samples' },
                yaxis: { title: 'Sample Size', range: [0, 7] },
                margin: { t: 50, b: 50, l: 60, r: 60 },
                responsive: true
            });

            // Feature Importance Chart
            const importanceData = [{
                x: [0.32, 0.28, 0.18, 0.15, 0.07],
                y: ['Sex', 'Fare', 'Age', 'Pclass', 'Embarked'],
                type: 'bar', orientation: 'h',
                marker: { color: ['#667eea', '#764ba2', '#667eea', '#764ba2', '#667eea'] }
            }];
            Plotly.newPlot('importanceViz', importanceData, {
                title: 'Feature Importance - Titanic Dataset',
                xaxis: { title: 'Importance Score' },
                margin: { l: 100, r: 50, t: 50, b: 50 },
                responsive: true
            });

            // Comparison Chart
            const comparisonData = [{
                r: [85, 70, 60, 90],
                theta: ['Accuracy', 'Speed', 'Interpretability', 'Robustness'],
                name: 'Random Forest',
                type: 'scatterpolar',
                fill: 'toself',
                marker: { color: '#667eea' }
            }, {
                r: [70, 95, 95, 50],
                theta: ['Accuracy', 'Speed', 'Interpretability', 'Robustness'],
                name: 'Decision Tree',
                type: 'scatterpolar',
                fill: 'toself',
                marker: { color: '#764ba2' }
            }];
            Plotly.newPlot('comparisonViz', comparisonData, {
                title: 'Random Forest vs Decision Tree',
                polar: { radialaxis: { visible: true, range: [0, 100] } },
                responsive: true
            });

            // Case Study Results
            const caseData = [{
                values: [86.5, 13.5],
                labels: ['Correct Predictions', 'Incorrect Predictions'],
                type: 'pie',
                marker: { colors: ['#28a745', '#dc3545'] }
            }];
            Plotly.newPlot('caseStudyViz', caseData, {
                title: 'Model Accuracy Distribution - 86.5%',
                margin: { t: 50, b: 50, l: 60, r: 60 },
                responsive: true
            });
        }

        // Initialize visualizations when page loads
        window.addEventListener('load', createVisualizations);
    </script>
</body>
</html>
